{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Define the specific order for adapter_config_string\n",
    "# adapter_order = ['full_tuning', 'houlsby', 'pfeiffer', 'scaled_parallel', 'ln_tuning',\n",
    "#                  'lora', 'hf_lora_all', 'hf_krona', 'compacter', 'compacter++', 'ia3',\n",
    "#                  'prefix_tuning[bottleneck_size=800,kv_size=64]|par_bn', 'prefix_tuning[kv_size=64]', 'prefix_tuning_flat[kv_size=64]', 'lora[r=8,use_gating=True]|prefix_tuning[prefix_length=10,use_gating=True,kv_size=64]|seq_bn[reduction_factor=16,use_gating=True]']\n",
    "adapter_order = ['full_tuning', 'houlsby', 'pfeiffer', 'scaled_parallel', 'ln_tuning',\n",
    "                 'lora', 'hf_lora', 'hf_lora_all', 'hf_krona', 'compacter', 'compacter++', 'ia3',\n",
    "                 'mam', 'prefix_tuning', 'prefix_tuning_flat', 'unipelt']\n",
    "adapter_order = adapter_order[::-1]\n",
    "\n",
    "dataset_config_order = [\"3.0.0\", \"boolq\", \"rte\", \"copa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique models: 0\n",
      "Unique adapter configs: 0\n",
      "(0, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>adapter_config_string</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_config_name</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>throughput_tokens</th>\n",
       "      <th>test/throughput_tokens</th>\n",
       "      <th>peak_memory_usage</th>\n",
       "      <th>eval/peak_memory_usage</th>\n",
       "      <th>test/peak_memory_usage</th>\n",
       "      <th>num_gpus</th>\n",
       "      <th>throughput_tokens_per_gpu</th>\n",
       "      <th>throughput_tokens_per_gpu_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, model_name_or_path, adapter_config_string, dataset_name, dataset_config_name, per_device_train_batch_size, gradient_accumulation_steps, throughput_tokens, test/throughput_tokens, peak_memory_usage, eval/peak_memory_usage, test/peak_memory_usage, num_gpus, throughput_tokens_per_gpu, throughput_tokens_per_gpu_test]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../wandb_results/wandb_export_2023-12-23T10_15_59.462-05_00.csv\")\n",
    "\n",
    "relevant_columns = ['Name', 'model_name_or_path', 'adapter_config_string',\n",
    "                    'dataset_name', 'dataset_config_name',\n",
    "                    'per_device_train_batch_size', 'gradient_accumulation_steps',\n",
    "                    'throughput_tokens', 'test/throughput_tokens',\n",
    "                    'total_batch_size',\n",
    "                    'peak_memory_usage', 'eval/peak_memory_usage', 'test/peak_memory_usage',\n",
    "                    ]\n",
    "\n",
    "df = df[relevant_columns]\n",
    "df = df.dropna()\n",
    "# df = df[df.model_name_or_path != \"t5-11b\"]\n",
    "\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning[bottleneck_size=800,kv_size=64]|par_bn\", \"mam\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning[bottleneck_size=800,kv_size=128]|par_bn\", \"mam\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning_flat[kv_size=128]\", \"prefix_tuning_flat\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning_flat[kv_size=64]\", \"prefix_tuning_flat\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning[kv_size=128]\", \"prefix_tuning\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning[kv_size=64]\", \"prefix_tuning\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"lora[r=8,use_gating=True]|prefix_tuning[prefix_length=10,use_gating=True,kv_size=128]|seq_bn[reduction_factor=16,use_gating=True]\", \"unipelt\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"lora[r=8,use_gating=True]|prefix_tuning[prefix_length=10,use_gating=True,kv_size=64]|seq_bn[reduction_factor=16,use_gating=True]\", \"unipelt\"\n",
    ")\n",
    "\n",
    "# num_gpus = total_batch_size / (per_device_train_batch_size * gradient_accumulation_steps)\n",
    "df = df.assign(num_gpus=df['total_batch_size'] / (\n",
    "        df['per_device_train_batch_size'] * df['gradient_accumulation_steps']))\n",
    "\n",
    "df = df.assign(\n",
    "    throughput_tokens_per_gpu=df['throughput_tokens'] / df['num_gpus'])\n",
    "\n",
    "df = df.assign(\n",
    "    throughput_tokens_per_gpu_test=df['test/throughput_tokens'] / df['num_gpus'])\n",
    "\n",
    "# table = df.groupby(\n",
    "#     ['model_name_or_path', 'adapter_config_string', 'num_gpus'])\\\n",
    "#     .agg({\n",
    "#         'total_parameters': 'mean',\n",
    "#         'trainable_parameters': 'mean',\n",
    "#         'throughput_tokens_per_gpu': ['mean', 'std'],\n",
    "#         'throughput_tokens_per_gpu_test': ['mean', 'std'],\n",
    "#         'Name': 'count',\n",
    "#     }).reset_index()\n",
    "\n",
    "df['adapter_config_string'] = df['adapter_config_string'].astype(\n",
    "    CategoricalDtype(categories=adapter_order, ordered=True)\n",
    ")\n",
    "df['dataset_config_name'] = df['dataset_config_name'].astype(\n",
    "    CategoricalDtype(categories=dataset_config_order, ordered=True)\n",
    ")\n",
    "df = df.sort_values(\n",
    "    by=['model_name_or_path', 'num_gpus', 'adapter_config_string', 'dataset_config_name'],\n",
    "    ascending=[False, True, False, True]\n",
    ")\n",
    "\n",
    "# remove column total_batch_size\n",
    "df = df.drop(columns=['total_batch_size'])\n",
    "\n",
    "print(\"Unique models:\", len(df['model_name_or_path'].unique()))\n",
    "print(\"Unique adapter configs:\", len(df['adapter_config_string'].unique()))\n",
    "\n",
    "print(df.shape)\n",
    "df.to_csv('../wandb_results/throughput_noaverage_evalonly.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test throughput table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>adapter_config_string</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_config_name</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>eval/throughput_tokens_mean</th>\n",
       "      <th>eval/throughput_tokens_std</th>\n",
       "      <th>total_batch_size</th>\n",
       "      <th>peak_memory_usage</th>\n",
       "      <th>eval/peak_memory_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glad-planet-2946</td>\n",
       "      <td>t5-11b</td>\n",
       "      <td>lora[r=8,use_gating=True]|prefix_tuning[prefix...</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>305.699457</td>\n",
       "      <td>33.227493</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24242.183105</td>\n",
       "      <td>24242.183105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>splendid-leaf-2945</td>\n",
       "      <td>t5-11b</td>\n",
       "      <td>prefix_tuning[bottleneck_size=800,kv_size=128]...</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>3.0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3260.064222</td>\n",
       "      <td>208.213074</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27090.796387</td>\n",
       "      <td>27090.796387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>likely-wave-2944</td>\n",
       "      <td>t5-11b</td>\n",
       "      <td>prefix_tuning_flat[kv_size=128]</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>467.299949</td>\n",
       "      <td>49.448879</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21958.032227</td>\n",
       "      <td>21958.476945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>true-cosmos-2943</td>\n",
       "      <td>t5-11b</td>\n",
       "      <td>prefix_tuning[kv_size=128]</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>449.217234</td>\n",
       "      <td>49.058655</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24281.101562</td>\n",
       "      <td>24281.101562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>divine-bush-2942</td>\n",
       "      <td>t5-11b</td>\n",
       "      <td>ia3</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>3.0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4242.824479</td>\n",
       "      <td>282.659058</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23229.260742</td>\n",
       "      <td>23229.260742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>daily-wildflower-2792</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>hf_lora</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23667.412848</td>\n",
       "      <td>4264.500977</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1624.643555</td>\n",
       "      <td>1790.048828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>olive-forest-2791</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>scaled_parallel</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17511.523876</td>\n",
       "      <td>3203.271729</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1779.057617</td>\n",
       "      <td>1941.204590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>decent-firebrand-2790</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>ln_tuning</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30371.497942</td>\n",
       "      <td>5562.807617</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1620.143555</td>\n",
       "      <td>1782.220703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>fresh-disco-2789</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>pfeiffer</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19303.642570</td>\n",
       "      <td>3444.671631</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1718.702148</td>\n",
       "      <td>1881.161621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>cool-snowball-2788</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>houlsby</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16497.748204</td>\n",
       "      <td>2955.653564</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1707.127930</td>\n",
       "      <td>1869.274902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name model_name_or_path  \\\n",
       "3         glad-planet-2946             t5-11b   \n",
       "4       splendid-leaf-2945             t5-11b   \n",
       "5         likely-wave-2944             t5-11b   \n",
       "6         true-cosmos-2943             t5-11b   \n",
       "7         divine-bush-2942             t5-11b   \n",
       "..                     ...                ...   \n",
       "157  daily-wildflower-2792           t5-large   \n",
       "158      olive-forest-2791           t5-large   \n",
       "159  decent-firebrand-2790           t5-large   \n",
       "160       fresh-disco-2789           t5-large   \n",
       "161     cool-snowball-2788           t5-large   \n",
       "\n",
       "                                 adapter_config_string   dataset_name  \\\n",
       "3    lora[r=8,use_gating=True]|prefix_tuning[prefix...     super_glue   \n",
       "4    prefix_tuning[bottleneck_size=800,kv_size=128]...  cnn_dailymail   \n",
       "5                      prefix_tuning_flat[kv_size=128]     super_glue   \n",
       "6                           prefix_tuning[kv_size=128]     super_glue   \n",
       "7                                                  ia3  cnn_dailymail   \n",
       "..                                                 ...            ...   \n",
       "157                                            hf_lora     super_glue   \n",
       "158                                    scaled_parallel     super_glue   \n",
       "159                                          ln_tuning     super_glue   \n",
       "160                                           pfeiffer     super_glue   \n",
       "161                                            houlsby     super_glue   \n",
       "\n",
       "    dataset_config_name  per_device_train_batch_size  \\\n",
       "3                  copa                          1.0   \n",
       "4                 3.0.0                          1.0   \n",
       "5                  copa                          1.0   \n",
       "6                  copa                          1.0   \n",
       "7                 3.0.0                          1.0   \n",
       "..                  ...                          ...   \n",
       "157                copa                         32.0   \n",
       "158                copa                         32.0   \n",
       "159                copa                         32.0   \n",
       "160                copa                         32.0   \n",
       "161                copa                         32.0   \n",
       "\n",
       "     gradient_accumulation_steps  eval/throughput_tokens_mean  \\\n",
       "3                           32.0                   305.699457   \n",
       "4                           32.0                  3260.064222   \n",
       "5                           32.0                   467.299949   \n",
       "6                           32.0                   449.217234   \n",
       "7                           32.0                  4242.824479   \n",
       "..                           ...                          ...   \n",
       "157                          1.0                 23667.412848   \n",
       "158                          1.0                 17511.523876   \n",
       "159                          1.0                 30371.497942   \n",
       "160                          1.0                 19303.642570   \n",
       "161                          1.0                 16497.748204   \n",
       "\n",
       "     eval/throughput_tokens_std  total_batch_size  peak_memory_usage  \\\n",
       "3                     33.227493              32.0       24242.183105   \n",
       "4                    208.213074              32.0       27090.796387   \n",
       "5                     49.448879              32.0       21958.032227   \n",
       "6                     49.058655              32.0       24281.101562   \n",
       "7                    282.659058              32.0       23229.260742   \n",
       "..                          ...               ...                ...   \n",
       "157                 4264.500977              32.0        1624.643555   \n",
       "158                 3203.271729              32.0        1779.057617   \n",
       "159                 5562.807617              32.0        1620.143555   \n",
       "160                 3444.671631              32.0        1718.702148   \n",
       "161                 2955.653564              32.0        1707.127930   \n",
       "\n",
       "     eval/peak_memory_usage  \n",
       "3              24242.183105  \n",
       "4              27090.796387  \n",
       "5              21958.476945  \n",
       "6              24281.101562  \n",
       "7              23229.260742  \n",
       "..                      ...  \n",
       "157             1790.048828  \n",
       "158             1941.204590  \n",
       "159             1782.220703  \n",
       "160             1881.161621  \n",
       "161             1869.274902  \n",
       "\n",
       "[159 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../wandb_results/wandb_export_2023-12-23T10_15_59.462-05_00.csv\")\n",
    "\n",
    "relevant_columns = ['Name', 'model_name_or_path', 'adapter_config_string',\n",
    "                    'dataset_name', 'dataset_config_name',\n",
    "                    'per_device_train_batch_size', 'gradient_accumulation_steps',\n",
    "                    'eval/throughput_tokens_mean', 'eval/throughput_tokens_std',\n",
    "                    'total_batch_size',\n",
    "                    'peak_memory_usage', 'eval/peak_memory_usage',\n",
    "                    ]\n",
    "\n",
    "df = df[relevant_columns]\n",
    "df = df.dropna()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique models: 3\n",
      "Unique adapter configs: 15\n",
      "(10, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>adapter_config_string</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_config_name</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>eval/throughput_tokens_mean</th>\n",
       "      <th>eval/throughput_tokens_std</th>\n",
       "      <th>peak_memory_usage</th>\n",
       "      <th>eval/peak_memory_usage</th>\n",
       "      <th>num_gpus</th>\n",
       "      <th>throughput_tokens_per_gpu_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noble-blaze-2976</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>compacter</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>3.0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16543.971600</td>\n",
       "      <td>266.527496</td>\n",
       "      <td>1927.661133</td>\n",
       "      <td>1927.661133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16543.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fanciful-silence-2975</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>compacter</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>boolq</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38839.069641</td>\n",
       "      <td>5884.388672</td>\n",
       "      <td>2268.171387</td>\n",
       "      <td>2795.844190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38839.069641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>honest-water-2973</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>compacter</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>rte</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49533.506632</td>\n",
       "      <td>4303.685059</td>\n",
       "      <td>2305.194824</td>\n",
       "      <td>3159.204054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49533.506632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>swift-darkness-2971</td>\n",
       "      <td>t5-large</td>\n",
       "      <td>compacter</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12976.799077</td>\n",
       "      <td>2392.590332</td>\n",
       "      <td>1683.597168</td>\n",
       "      <td>1845.744141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12976.799077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficient-energy-2979</td>\n",
       "      <td>t5-3b</td>\n",
       "      <td>compacter</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>3.0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4239.623007</td>\n",
       "      <td>586.033752</td>\n",
       "      <td>5904.960449</td>\n",
       "      <td>5904.960449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4239.623007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vocal-night-2977</td>\n",
       "      <td>t5-3b</td>\n",
       "      <td>compacter</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>boolq</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3127.520970</td>\n",
       "      <td>970.247192</td>\n",
       "      <td>5928.335449</td>\n",
       "      <td>5928.335449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3127.520970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>graceful-dew-2973</td>\n",
       "      <td>t5-3b</td>\n",
       "      <td>compacter</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>rte</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4581.579083</td>\n",
       "      <td>1566.018188</td>\n",
       "      <td>6050.745605</td>\n",
       "      <td>6091.258808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4581.579083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>honest-morning-2972</td>\n",
       "      <td>t5-3b</td>\n",
       "      <td>compacter</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1567.368689</td>\n",
       "      <td>144.680191</td>\n",
       "      <td>5733.413086</td>\n",
       "      <td>5733.413086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1567.368689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glowing-snowball-2978</td>\n",
       "      <td>t5-11b</td>\n",
       "      <td>compacter</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>rte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>718.281145</td>\n",
       "      <td>377.803894</td>\n",
       "      <td>22202.440918</td>\n",
       "      <td>22279.650237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>718.281145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sleek-galaxy-2970</td>\n",
       "      <td>t5-11b</td>\n",
       "      <td>compacter</td>\n",
       "      <td>super_glue</td>\n",
       "      <td>copa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>345.946850</td>\n",
       "      <td>36.218567</td>\n",
       "      <td>21815.406738</td>\n",
       "      <td>21815.406738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>345.946850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name model_name_or_path adapter_config_string  \\\n",
       "4        noble-blaze-2976           t5-large             compacter   \n",
       "5   fanciful-silence-2975           t5-large             compacter   \n",
       "7       honest-water-2973           t5-large             compacter   \n",
       "8     swift-darkness-2971           t5-large             compacter   \n",
       "1   efficient-energy-2979              t5-3b             compacter   \n",
       "3        vocal-night-2977              t5-3b             compacter   \n",
       "6       graceful-dew-2973              t5-3b             compacter   \n",
       "9     honest-morning-2972              t5-3b             compacter   \n",
       "2   glowing-snowball-2978             t5-11b             compacter   \n",
       "10      sleek-galaxy-2970             t5-11b             compacter   \n",
       "\n",
       "     dataset_name dataset_config_name  per_device_train_batch_size  \\\n",
       "4   cnn_dailymail               3.0.0                          4.0   \n",
       "5      super_glue               boolq                         16.0   \n",
       "7      super_glue                 rte                         32.0   \n",
       "8      super_glue                copa                         32.0   \n",
       "1   cnn_dailymail               3.0.0                          1.0   \n",
       "3      super_glue               boolq                          2.0   \n",
       "6      super_glue                 rte                          4.0   \n",
       "9      super_glue                copa                          4.0   \n",
       "2      super_glue                 rte                          1.0   \n",
       "10     super_glue                copa                          1.0   \n",
       "\n",
       "    gradient_accumulation_steps  eval/throughput_tokens_mean  \\\n",
       "4                           8.0                 16543.971600   \n",
       "5                           2.0                 38839.069641   \n",
       "7                           1.0                 49533.506632   \n",
       "8                           1.0                 12976.799077   \n",
       "1                          32.0                  4239.623007   \n",
       "3                          16.0                  3127.520970   \n",
       "6                           8.0                  4581.579083   \n",
       "9                           8.0                  1567.368689   \n",
       "2                          32.0                   718.281145   \n",
       "10                         32.0                   345.946850   \n",
       "\n",
       "    eval/throughput_tokens_std  peak_memory_usage  eval/peak_memory_usage  \\\n",
       "4                   266.527496        1927.661133             1927.661133   \n",
       "5                  5884.388672        2268.171387             2795.844190   \n",
       "7                  4303.685059        2305.194824             3159.204054   \n",
       "8                  2392.590332        1683.597168             1845.744141   \n",
       "1                   586.033752        5904.960449             5904.960449   \n",
       "3                   970.247192        5928.335449             5928.335449   \n",
       "6                  1566.018188        6050.745605             6091.258808   \n",
       "9                   144.680191        5733.413086             5733.413086   \n",
       "2                   377.803894       22202.440918            22279.650237   \n",
       "10                   36.218567       21815.406738            21815.406738   \n",
       "\n",
       "    num_gpus  throughput_tokens_per_gpu_test  \n",
       "4        1.0                    16543.971600  \n",
       "5        1.0                    38839.069641  \n",
       "7        1.0                    49533.506632  \n",
       "8        1.0                    12976.799077  \n",
       "1        1.0                     4239.623007  \n",
       "3        1.0                     3127.520970  \n",
       "6        1.0                     4581.579083  \n",
       "9        1.0                     1567.368689  \n",
       "2        1.0                      718.281145  \n",
       "10       1.0                      345.946850  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../wandb_results/wandb_export_2023-12-23T11_41_11.610-05_00.csv\")\n",
    "\n",
    "relevant_columns = ['Name', 'model_name_or_path', 'adapter_config_string',\n",
    "                    'dataset_name', 'dataset_config_name',\n",
    "                    'per_device_train_batch_size', 'gradient_accumulation_steps',\n",
    "                    'eval/throughput_tokens_mean', 'eval/throughput_tokens_std',\n",
    "                    'total_batch_size',\n",
    "                    'peak_memory_usage', 'eval/peak_memory_usage',\n",
    "                    ]\n",
    "\n",
    "df = df[relevant_columns]\n",
    "df = df.dropna()\n",
    "# df = df[df.model_name_or_path != \"t5-11b\"]\n",
    "\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning[bottleneck_size=800,kv_size=64]|par_bn\", \"mam\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning[bottleneck_size=800,kv_size=128]|par_bn\", \"mam\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning_flat[kv_size=128]\", \"prefix_tuning_flat\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning_flat[kv_size=64]\", \"prefix_tuning_flat\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning[kv_size=128]\", \"prefix_tuning\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"prefix_tuning[kv_size=64]\", \"prefix_tuning\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"lora[r=8,use_gating=True]|prefix_tuning[prefix_length=10,use_gating=True,kv_size=128]|seq_bn[reduction_factor=16,use_gating=True]\", \"unipelt\"\n",
    ")\n",
    "df['adapter_config_string'] = df['adapter_config_string'].replace(\n",
    "    \"lora[r=8,use_gating=True]|prefix_tuning[prefix_length=10,use_gating=True,kv_size=64]|seq_bn[reduction_factor=16,use_gating=True]\", \"unipelt\"\n",
    ")\n",
    "\n",
    "# num_gpus = total_batch_size / (per_device_train_batch_size * gradient_accumulation_steps)\n",
    "df = df.assign(num_gpus=df['total_batch_size'] / (\n",
    "        df['per_device_train_batch_size'] * df['gradient_accumulation_steps']))\n",
    "\n",
    "df = df.assign(\n",
    "    throughput_tokens_per_gpu_test=df['eval/throughput_tokens_mean'] / df['num_gpus'])\n",
    "\n",
    "# table = df.groupby(\n",
    "#     ['model_name_or_path', 'adapter_config_string', 'num_gpus'])\\\n",
    "#     .agg({\n",
    "#         'total_parameters': 'mean',\n",
    "#         'trainable_parameters': 'mean',\n",
    "#         'throughput_tokens_per_gpu': ['mean', 'std'],\n",
    "#         'throughput_tokens_per_gpu_test': ['mean', 'std'],\n",
    "#         'Name': 'count',\n",
    "#     }).reset_index()\n",
    "\n",
    "df['adapter_config_string'] = df['adapter_config_string'].astype(\n",
    "    CategoricalDtype(categories=adapter_order, ordered=True)\n",
    ")\n",
    "df['dataset_config_name'] = df['dataset_config_name'].astype(\n",
    "    CategoricalDtype(categories=dataset_config_order, ordered=True)\n",
    ")\n",
    "df = df.sort_values(\n",
    "    by=['model_name_or_path', 'num_gpus', 'adapter_config_string', 'dataset_config_name'],\n",
    "    ascending=[False, True, False, True]\n",
    ")\n",
    "\n",
    "# remove column total_batch_size\n",
    "df = df.drop(columns=['total_batch_size'])\n",
    "\n",
    "print(\"Unique models:\", len(df['model_name_or_path'].unique()))\n",
    "print(\"Unique adapter configs:\", len(df['adapter_config_string'].unique()))\n",
    "\n",
    "df = df[df[\"adapter_config_string\"] == \"compacter\"]\n",
    "\n",
    "print(df.shape)\n",
    "df.to_csv('../wandb_results/throughput_noaverage_evalonly_compacter.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft_comparison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
